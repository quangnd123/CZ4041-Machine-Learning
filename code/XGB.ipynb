{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8ac4ad",
   "metadata": {},
   "source": [
    "# All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b4a73e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9eae91",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07158946",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aea3e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2016 = pd.read_csv('./../preprocessed data/df_train_2016.csv')\n",
    "predict_2016 = pd.read_csv('./../preprocessed data/df_predict_2016.csv')\n",
    "\n",
    "train_2017 = pd.read_csv('./../preprocessed data/df_train_2017.csv')\n",
    "predict_2017 = pd.read_csv('./../preprocessed data/df_predict_2017.csv')\n",
    "\n",
    "sample = pd.read_csv(\"./../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e0cac",
   "metadata": {},
   "source": [
    "# Processing Data (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2cce56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2016 = train_2016.drop(['logerror'], axis=1)\n",
    "num_columns = x_train_2016.columns\n",
    "y_train_2016 = train_2016['logerror'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a02737fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Outliers\n",
    "train_2016=train_2016[train_2016.logerror > -0.4 ]\n",
    "train_2016=train_2016[train_2016.logerror < 0.418 ]\n",
    "x_train_2016 = train_2016.drop(['logerror'], axis=1)\n",
    "y_train_2016 = train_2016['logerror'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "71b9bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train_2016, y_train_2016, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336039d2",
   "metadata": {},
   "source": [
    "# Creating DMatrix (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "71d82cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_2016 = xgb.DMatrix(x_train, y_train)\n",
    "test_matrix_2016 = xgb.DMatrix(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "af6f31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(y_train)\n",
    "xgb_params = {\n",
    "    'max_depth':9,\n",
    "    'min_child_weight': 5,\n",
    "    'eta':.01,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective':'reg:linear',\n",
    "    'silent': 1,\n",
    "    'base_score': mean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c4026d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:40:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[0]\ttrain-rmse:0.08328\ttest-rmse:0.08379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:0.08299\ttest-rmse:0.08370\n",
      "[20]\ttrain-rmse:0.08275\ttest-rmse:0.08362\n",
      "[30]\ttrain-rmse:0.08251\ttest-rmse:0.08355\n",
      "[40]\ttrain-rmse:0.08229\ttest-rmse:0.08349\n",
      "[50]\ttrain-rmse:0.08208\ttest-rmse:0.08344\n",
      "[60]\ttrain-rmse:0.08190\ttest-rmse:0.08340\n",
      "[70]\ttrain-rmse:0.08171\ttest-rmse:0.08336\n",
      "[80]\ttrain-rmse:0.08152\ttest-rmse:0.08332\n",
      "[90]\ttrain-rmse:0.08135\ttest-rmse:0.08328\n",
      "[100]\ttrain-rmse:0.08119\ttest-rmse:0.08325\n",
      "[110]\ttrain-rmse:0.08104\ttest-rmse:0.08323\n",
      "[120]\ttrain-rmse:0.08089\ttest-rmse:0.08321\n",
      "[130]\ttrain-rmse:0.08075\ttest-rmse:0.08318\n",
      "[140]\ttrain-rmse:0.08062\ttest-rmse:0.08317\n",
      "[150]\ttrain-rmse:0.08050\ttest-rmse:0.08316\n",
      "[160]\ttrain-rmse:0.08038\ttest-rmse:0.08314\n",
      "[170]\ttrain-rmse:0.08024\ttest-rmse:0.08311\n",
      "[180]\ttrain-rmse:0.08012\ttest-rmse:0.08310\n",
      "[190]\ttrain-rmse:0.08001\ttest-rmse:0.08308\n",
      "[200]\ttrain-rmse:0.07988\ttest-rmse:0.08307\n",
      "[210]\ttrain-rmse:0.07978\ttest-rmse:0.08306\n",
      "[220]\ttrain-rmse:0.07967\ttest-rmse:0.08305\n",
      "[230]\ttrain-rmse:0.07958\ttest-rmse:0.08304\n",
      "[240]\ttrain-rmse:0.07948\ttest-rmse:0.08303\n",
      "[250]\ttrain-rmse:0.07938\ttest-rmse:0.08302\n",
      "[260]\ttrain-rmse:0.07929\ttest-rmse:0.08301\n",
      "[270]\ttrain-rmse:0.07920\ttest-rmse:0.08300\n",
      "[280]\ttrain-rmse:0.07911\ttest-rmse:0.08299\n",
      "[290]\ttrain-rmse:0.07901\ttest-rmse:0.08298\n",
      "[300]\ttrain-rmse:0.07893\ttest-rmse:0.08297\n",
      "[310]\ttrain-rmse:0.07885\ttest-rmse:0.08297\n",
      "[320]\ttrain-rmse:0.07878\ttest-rmse:0.08297\n",
      "[330]\ttrain-rmse:0.07871\ttest-rmse:0.08297\n",
      "[340]\ttrain-rmse:0.07862\ttest-rmse:0.08297\n",
      "[350]\ttrain-rmse:0.07854\ttest-rmse:0.08297\n",
      "[360]\ttrain-rmse:0.07848\ttest-rmse:0.08297\n",
      "[370]\ttrain-rmse:0.07839\ttest-rmse:0.08296\n",
      "[380]\ttrain-rmse:0.07831\ttest-rmse:0.08296\n",
      "[390]\ttrain-rmse:0.07822\ttest-rmse:0.08296\n",
      "[400]\ttrain-rmse:0.07815\ttest-rmse:0.08296\n",
      "[410]\ttrain-rmse:0.07808\ttest-rmse:0.08296\n",
      "[420]\ttrain-rmse:0.07801\ttest-rmse:0.08295\n",
      "[430]\ttrain-rmse:0.07793\ttest-rmse:0.08295\n",
      "[440]\ttrain-rmse:0.07786\ttest-rmse:0.08294\n",
      "[450]\ttrain-rmse:0.07779\ttest-rmse:0.08294\n",
      "[460]\ttrain-rmse:0.07771\ttest-rmse:0.08294\n",
      "[470]\ttrain-rmse:0.07762\ttest-rmse:0.08294\n",
      "[480]\ttrain-rmse:0.07754\ttest-rmse:0.08294\n",
      "[490]\ttrain-rmse:0.07747\ttest-rmse:0.08294\n",
      "[500]\ttrain-rmse:0.07741\ttest-rmse:0.08294\n",
      "[510]\ttrain-rmse:0.07733\ttest-rmse:0.08294\n",
      "[520]\ttrain-rmse:0.07725\ttest-rmse:0.08293\n",
      "[530]\ttrain-rmse:0.07717\ttest-rmse:0.08293\n",
      "[540]\ttrain-rmse:0.07709\ttest-rmse:0.08292\n",
      "[550]\ttrain-rmse:0.07702\ttest-rmse:0.08292\n",
      "[560]\ttrain-rmse:0.07697\ttest-rmse:0.08292\n",
      "[570]\ttrain-rmse:0.07689\ttest-rmse:0.08292\n",
      "[580]\ttrain-rmse:0.07683\ttest-rmse:0.08292\n",
      "[590]\ttrain-rmse:0.07675\ttest-rmse:0.08292\n",
      "[600]\ttrain-rmse:0.07669\ttest-rmse:0.08292\n",
      "[610]\ttrain-rmse:0.07661\ttest-rmse:0.08291\n",
      "[620]\ttrain-rmse:0.07655\ttest-rmse:0.08292\n",
      "[630]\ttrain-rmse:0.07647\ttest-rmse:0.08292\n",
      "[640]\ttrain-rmse:0.07640\ttest-rmse:0.08292\n",
      "[650]\ttrain-rmse:0.07633\ttest-rmse:0.08292\n",
      "[660]\ttrain-rmse:0.07628\ttest-rmse:0.08292\n",
      "[670]\ttrain-rmse:0.07621\ttest-rmse:0.08292\n",
      "[680]\ttrain-rmse:0.07616\ttest-rmse:0.08291\n",
      "[690]\ttrain-rmse:0.07609\ttest-rmse:0.08292\n",
      "[700]\ttrain-rmse:0.07603\ttest-rmse:0.08292\n",
      "[710]\ttrain-rmse:0.07597\ttest-rmse:0.08292\n",
      "[720]\ttrain-rmse:0.07590\ttest-rmse:0.08292\n",
      "[730]\ttrain-rmse:0.07585\ttest-rmse:0.08292\n",
      "[740]\ttrain-rmse:0.07579\ttest-rmse:0.08292\n",
      "[750]\ttrain-rmse:0.07575\ttest-rmse:0.08292\n",
      "[760]\ttrain-rmse:0.07569\ttest-rmse:0.08293\n",
      "[770]\ttrain-rmse:0.07562\ttest-rmse:0.08292\n",
      "[780]\ttrain-rmse:0.07556\ttest-rmse:0.08293\n",
      "[783]\ttrain-rmse:0.07554\ttest-rmse:0.08293\n",
      "Best MAE: 0.08 with 684 rounds\n"
     ]
    }
   ],
   "source": [
    "xgb_params['eval_metric']:\"mae\"\n",
    "num_boost_round = 999\n",
    "early_stopping_rounds = 10\n",
    "model = xgb.train(xgb_params, train_matrix_2016, 100000, [(train_matrix_2016, 'train'), (test_matrix_2016, 'test')], early_stopping_rounds=100, verbose_eval=10)\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6ab54",
   "metadata": {},
   "source": [
    "# Finding Optimal Parameters (2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8dc19",
   "metadata": {},
   "source": [
    "# max_depth, min_child_weight (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "57ebb1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngridsearch_params = [\\n    (max_depth, min_child_weight)\\n    for max_depth in range(9,12)\\n    for min_child_weight in range(5,8)\\n]\\n\\nmin_mae = float(\"Inf\")\\nbest_params = None\\nfor max_depth, min_child_weight in gridsearch_params:\\n    print(\"CV with max_depth={}, min_child_weight={}\".format(\\n                             max_depth,\\n                             min_child_weight))\\n    # Update our parameters\\n    params[\\'max_depth\\'] = max_depth\\n    params[\\'min_child_weight\\'] = min_child_weight\\n    # Run CV\\n    cv_results = xgb.cv(\\n        xgb_params,\\n        train_matrix_2016,\\n        num_boost_round=num_boost_round,\\n        nfold=5,\\n        seed=42,\\n        metrics={\\'mae\\'},\\n        early_stopping_rounds=early_stopping_rounds\\n    )\\n    # Update best MAE\\n    mean_mae = cv_results[\\'test-mae-mean\\'].min()\\n    boost_rounds = cv_results[\\'test-mae-mean\\'].argmin()\\n    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\\n    if mean_mae < min_mae:\\n        min_mae = mean_mae\\n        best_params = (max_depth,min_child_weight)\\nprint(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        xgb_params,\n",
    "        train_matrix_2016,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=5,\n",
    "        seed=42,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=early_stopping_rounds\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997147d8",
   "metadata": {},
   "source": [
    "# subsample, colsample_bytree (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8b47a420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngridsearch_params = [\\n    (subsample, colsample)\\n    for subsample in [i/10. for i in range(7,11)]\\n    for colsample in [i/10. for i in range(7,11)]\\n]\\n\\nmin_mae = float(\"Inf\")\\nbest_params = None\\n# We start by the largest values and go down to the smallest\\nfor subsample, colsample in reversed(gridsearch_params):\\n    print(\"CV with subsample={}, colsample={}\".format(\\n                             subsample,\\n                             colsample))\\n    # We update our parameters\\n    params[\\'subsample\\'] = subsample\\n    params[\\'colsample_bytree\\'] = colsample\\n    # Run CV\\n    cv_results = xgb.cv(\\n        xgb_params,\\n        train_matrix_2016,\\n        num_boost_round=num_boost_round,\\n        nfold=5,\\n        seed=42,\\n        metrics={\\'mae\\'},\\n        early_stopping_rounds=early_stopping_rounds\\n    )\\n    # Update best score\\n    mean_mae = cv_results[\\'test-mae-mean\\'].min()\\n    boost_rounds = cv_results[\\'test-mae-mean\\'].argmin()\\n    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\\n    if mean_mae < min_mae:\\n        min_mae = mean_mae\\n        best_params = (subsample,colsample)\\nprint(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\\n'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        xgb_params,\n",
    "        train_matrix_2016,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=5,\n",
    "        seed=42,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=early_stopping_rounds\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e63aa7",
   "metadata": {},
   "source": [
    "# eta (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2533c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmin_mae = float(\"Inf\")\\nbest_params = None\\nfor eta in [.3, .2, .1, .05, .01, .005]:\\n    print(\"CV with eta={}\".format(eta))\\n    # We update our parameters\\n    params[\\'eta\\'] = eta\\n    # Run and time CV\\n    %time cv_results = xgb.cv(xgb_params,train_matrix_2016,num_boost_round=num_boost_round,nfold=5,seed=42,metrics={\\'mae\\'},early_stopping_rounds=early_stopping_rounds)\\n    # Update best score\\n    mean_mae = cv_results[\\'test-mae-mean\\'].min()\\n    boost_rounds = cv_results[\\'test-mae-mean\\'].argmin()\\n    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\\n    if mean_mae < min_mae:\\n        min_mae = mean_mae\\n        best_params = eta\\nprint(\"Best params: {}, MAE: {}\".format(best_params, min_mae))\\n'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(xgb_params,train_matrix_2016,num_boost_round=num_boost_round,nfold=5,seed=42,metrics={'mae'},early_stopping_rounds=early_stopping_rounds)\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "387ff719",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['parcelid'] = sample['ParcelId']\n",
    "\n",
    "df_test_2016 = sample.merge(predict_2016, on='parcelid', how='left')\n",
    "\n",
    "x_2016 = df_test_2016[num_columns]\n",
    "    \n",
    "matrix_2016 = xgb.DMatrix(x_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "123424f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = model.predict(matrix_2016)\n",
    "y_values = []\n",
    "\n",
    "for num,predict in enumerate(prediction_data):\n",
    "    y_values.append(str(round(predict,4)))\n",
    "    \n",
    "y_values=np.array(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab84fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.pop('parcelid')\n",
    "sample['201610'] = y_values\n",
    "sample['201611'] = y_values\n",
    "sample['201612'] = y_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0047063",
   "metadata": {},
   "source": [
    "# Processing Data (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7ab688f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2017 = train_2017.drop(['logerror'], axis=1)\n",
    "num_columns = x_train_2017.columns\n",
    "y_train_2017 = train_2017['logerror'].values.astype(np.float32)\n",
    "#print(len(y_train_2016))\n",
    "#print(x_train_2016.shape, y_train_2016.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b45f1c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Outliers\n",
    "train_2017=train_2017[train_2017.logerror > -0.4 ]\n",
    "train_2017=train_2017[train_2017.logerror < 0.418 ]\n",
    "x_train_2017 = train_2017.drop(['logerror'], axis=1)\n",
    "y_train_2017 = train_2017['logerror'].values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8e3cf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train_2017, y_train_2017, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a6532e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(y_train)\n",
    "xgb_params = {\n",
    "    'max_depth':9,\n",
    "    'min_child_weight': 5,\n",
    "    'eta':.01,\n",
    "    'subsample': 0.6,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective':'reg:linear',\n",
    "    'silent': 1,\n",
    "    'base_score': mean\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4703fd",
   "metadata": {},
   "source": [
    "# Creating DMatrix (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "51eb7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_2017 = xgb.DMatrix(x_train, y_train)\n",
    "test_matrix_2017 = xgb.DMatrix(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "65df669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:42:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[0]\ttrain-rmse:0.08247\ttest-rmse:0.08283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:617: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:0.08221\ttest-rmse:0.08276\n",
      "[20]\ttrain-rmse:0.08195\ttest-rmse:0.08269\n",
      "[30]\ttrain-rmse:0.08172\ttest-rmse:0.08263\n",
      "[40]\ttrain-rmse:0.08151\ttest-rmse:0.08258\n",
      "[50]\ttrain-rmse:0.08131\ttest-rmse:0.08254\n",
      "[60]\ttrain-rmse:0.08110\ttest-rmse:0.08249\n",
      "[70]\ttrain-rmse:0.08092\ttest-rmse:0.08246\n",
      "[80]\ttrain-rmse:0.08074\ttest-rmse:0.08243\n",
      "[90]\ttrain-rmse:0.08060\ttest-rmse:0.08241\n",
      "[100]\ttrain-rmse:0.08044\ttest-rmse:0.08238\n",
      "[110]\ttrain-rmse:0.08029\ttest-rmse:0.08236\n",
      "[120]\ttrain-rmse:0.08016\ttest-rmse:0.08234\n",
      "[130]\ttrain-rmse:0.08002\ttest-rmse:0.08233\n",
      "[140]\ttrain-rmse:0.07990\ttest-rmse:0.08232\n",
      "[150]\ttrain-rmse:0.07977\ttest-rmse:0.08230\n",
      "[160]\ttrain-rmse:0.07965\ttest-rmse:0.08230\n",
      "[170]\ttrain-rmse:0.07953\ttest-rmse:0.08229\n",
      "[180]\ttrain-rmse:0.07941\ttest-rmse:0.08228\n",
      "[190]\ttrain-rmse:0.07930\ttest-rmse:0.08227\n",
      "[200]\ttrain-rmse:0.07918\ttest-rmse:0.08226\n",
      "[210]\ttrain-rmse:0.07909\ttest-rmse:0.08226\n",
      "[220]\ttrain-rmse:0.07897\ttest-rmse:0.08226\n",
      "[230]\ttrain-rmse:0.07888\ttest-rmse:0.08226\n",
      "[240]\ttrain-rmse:0.07878\ttest-rmse:0.08225\n",
      "[250]\ttrain-rmse:0.07868\ttest-rmse:0.08225\n",
      "[260]\ttrain-rmse:0.07858\ttest-rmse:0.08225\n",
      "[270]\ttrain-rmse:0.07850\ttest-rmse:0.08225\n",
      "[280]\ttrain-rmse:0.07842\ttest-rmse:0.08224\n",
      "[290]\ttrain-rmse:0.07831\ttest-rmse:0.08223\n",
      "[300]\ttrain-rmse:0.07823\ttest-rmse:0.08224\n",
      "[310]\ttrain-rmse:0.07815\ttest-rmse:0.08223\n",
      "[320]\ttrain-rmse:0.07807\ttest-rmse:0.08223\n",
      "[330]\ttrain-rmse:0.07796\ttest-rmse:0.08223\n",
      "[340]\ttrain-rmse:0.07789\ttest-rmse:0.08222\n",
      "[350]\ttrain-rmse:0.07777\ttest-rmse:0.08222\n",
      "[360]\ttrain-rmse:0.07768\ttest-rmse:0.08222\n",
      "[370]\ttrain-rmse:0.07760\ttest-rmse:0.08221\n",
      "[380]\ttrain-rmse:0.07752\ttest-rmse:0.08222\n",
      "[390]\ttrain-rmse:0.07744\ttest-rmse:0.08222\n",
      "[400]\ttrain-rmse:0.07736\ttest-rmse:0.08222\n",
      "[410]\ttrain-rmse:0.07729\ttest-rmse:0.08222\n",
      "[420]\ttrain-rmse:0.07721\ttest-rmse:0.08222\n",
      "[430]\ttrain-rmse:0.07714\ttest-rmse:0.08222\n",
      "[440]\ttrain-rmse:0.07706\ttest-rmse:0.08222\n",
      "[450]\ttrain-rmse:0.07699\ttest-rmse:0.08222\n",
      "[457]\ttrain-rmse:0.07693\ttest-rmse:0.08221\n",
      "Best MAE: 0.08 with 358 rounds\n"
     ]
    }
   ],
   "source": [
    "xgb_params['eval_metric']:\"mae\"\n",
    "num_boost_round = 999\n",
    "early_stopping_rounds = 10\n",
    "model = xgb.train(xgb_params, train_matrix_2017, 100000, [(train_matrix_2017, 'train'), (test_matrix_2017, 'test')], early_stopping_rounds=100, verbose_eval=10)\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc8fab",
   "metadata": {},
   "source": [
    "# Finding Optimal Parameters (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d605ba3",
   "metadata": {},
   "source": [
    "# max_depth, min_child_weight (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dba746ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngridsearch_params = [\\n    (max_depth, min_child_weight)\\n    for max_depth in range(9,12)\\n    for min_child_weight in range(5,8)\\n]\\n\\nmin_mae = float(\"Inf\")\\nbest_params = None\\nfor max_depth, min_child_weight in gridsearch_params:\\n    print(\"CV with max_depth={}, min_child_weight={}\".format(\\n                             max_depth,\\n                             min_child_weight))\\n    # Update our parameters\\n    params[\\'max_depth\\'] = max_depth\\n    params[\\'min_child_weight\\'] = min_child_weight\\n    # Run CV\\n    cv_results = xgb.cv(\\n        xgb_params,\\n        train_matrix_2017,\\n        num_boost_round=num_boost_round,\\n        nfold=5,\\n        seed=42,\\n        metrics={\\'mae\\'},\\n        early_stopping_rounds=early_stopping_rounds\\n    )\\n    # Update best MAE\\n    mean_mae = cv_results[\\'test-mae-mean\\'].min()\\n    boost_rounds = cv_results[\\'test-mae-mean\\'].argmin()\\n    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\\n    if mean_mae < min_mae:\\n        min_mae = mean_mae\\n        best_params = (max_depth,min_child_weight)\\nprint(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\\n'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        xgb_params,\n",
    "        train_matrix_2017,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=5,\n",
    "        seed=42,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=early_stopping_rounds\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e4a0c",
   "metadata": {},
   "source": [
    "# subsample, colsample_bytree (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0eea2109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngridsearch_params = [\\n    (subsample, colsample)\\n    for subsample in [i/10. for i in range(7,11)]\\n    for colsample in [i/10. for i in range(7,11)]\\n]\\n\\nmin_mae = float(\"Inf\")\\nbest_params = None\\n# We start by the largest values and go down to the smallest\\nfor subsample, colsample in reversed(gridsearch_params):\\n    print(\"CV with subsample={}, colsample={}\".format(\\n                             subsample,\\n                             colsample))\\n    # We update our parameters\\n    params[\\'subsample\\'] = subsample\\n    params[\\'colsample_bytree\\'] = colsample\\n    # Run CV\\n    cv_results = xgb.cv(\\n        xgb_params,\\n        train_matrix_2017,\\n        num_boost_round=num_boost_round,\\n        nfold=5,\\n        seed=42,\\n        metrics={\\'mae\\'},\\n        early_stopping_rounds=early_stopping_rounds\\n    )\\n    # Update best score\\n    mean_mae = cv_results[\\'test-mae-mean\\'].min()\\n    boost_rounds = cv_results[\\'test-mae-mean\\'].argmin()\\n    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\\n    if mean_mae < min_mae:\\n        min_mae = mean_mae\\n        best_params = (subsample,colsample)\\nprint(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\\n'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        xgb_params,\n",
    "        train_matrix_2017,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=5,\n",
    "        seed=42,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=early_stopping_rounds\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55154709",
   "metadata": {},
   "source": [
    "# eta (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e452f526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmin_mae = float(\"Inf\")\\nbest_params = None\\nfor eta in [.3, .2, .1, .05, .01, .005]:\\n    print(\"CV with eta={}\".format(eta))\\n    # We update our parameters\\n    params[\\'eta\\'] = eta\\n    # Run and time CV\\n    %time cv_results = xgb.cv(xgb_params,train_matrix_2017,num_boost_round=num_boost_round,nfold=5,seed=42,metrics={\\'mae\\'},early_stopping_rounds=early_stopping_rounds)\\n    # Update best score\\n    mean_mae = cv_results[\\'test-mae-mean\\'].min()\\n    boost_rounds = cv_results[\\'test-mae-mean\\'].argmin()\\n    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\\n    if mean_mae < min_mae:\\n        min_mae = mean_mae\\n        best_params = eta\\nprint(\"Best params: {}, MAE: {}\".format(best_params, min_mae))\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(xgb_params,train_matrix_2017,num_boost_round=num_boost_round,nfold=5,seed=42,metrics={'mae'},early_stopping_rounds=early_stopping_rounds)\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5f6046e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['parcelid'] = sample['ParcelId']\n",
    "\n",
    "df_test_2017 = sample.merge(predict_2017, on='parcelid', how='left')\n",
    "\n",
    "x_2017 = df_test_2017[num_columns]\n",
    "    \n",
    "matrix_2017 = xgb.DMatrix(x_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1ea9f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = model.predict(matrix_2017)\n",
    "y_values = []\n",
    "\n",
    "for num,predict in enumerate(prediction_data):\n",
    "    y_values.append(str(round(predict,4)))\n",
    "    \n",
    "y_values=np.array(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5f755714",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.pop('parcelid')\n",
    "sample['201710'] = y_values\n",
    "sample['201711'] = y_values\n",
    "sample['201712'] = y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "808128bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('./../submission/xgb.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa085507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
